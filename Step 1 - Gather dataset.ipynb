{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathing the foundational dataset that this project will be based on\n",
    "\n",
    "What: Granted Design patents from the USPTO that were applied during the years 1980-2015\n",
    "\n",
    "How: Using the PatentsView API, which already disambiguates and aggregates patent data for us. This is a product directly from USPTO, makig it a realiable source. \n",
    "\n",
    "Data fields we are interested in:\n",
    "1. patent number\n",
    "2. application year\n",
    "3. number of inventors\n",
    "4. number of assignees\n",
    "5. number of cited design patents\n",
    "6. number of cited utility patents\n",
    "7. number of cited non-patent prior arts\n",
    "8. assignee name\n",
    "9. assignee city\n",
    "10. assignee state\n",
    "11. assignee country\n",
    "12. grant year\n",
    "13. priority date\n",
    "14. if cited any foreign patents\n",
    "15. design patent class\n",
    "16. design patent subclass\n",
    "17. number of figures\n",
    "18. if US inventor\n",
    "19. if any missing citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This particular API doesn't quite follow the standard REST protocol\n",
    "#This is setting up the parts of the URL that won't change between patents\n",
    "#See http://www.patentsview.org/api/query-language.html for more info\n",
    "\n",
    "\n",
    "base_url = \"http://www.patentsview.org/api/patents/query?\"\n",
    "field_list = \"&f=[\\\"patent_number\\\",\\\"app_date\\\",\\\"inventor_id\\\",\\\"assignee_city\\\",\\\"assignee_country\\\",\\\"assignee_state\\\",\\\"assignee_organization\\\",\\\"patent_year\\\",\\\"uspc_subclass_id\\\",\\\"uspc_mainclass_id\\\",\\\"cited_patent_number\\\",\\\"patent_num_foreign_citations\\\",\\\"patent_num_us_patent_citations\\\",\\\"forprior_country\\\", \\\"forprior_date\\\", \\\"patent_firstnamed_inventor_country\\\"]\"\n",
    "\n",
    "top_level = pd.DataFrame()\n",
    "applications_level = pd.DataFrame()\n",
    "assignee_level = pd.DataFrame()\n",
    "cited_patents_level = pd.DataFrame()\n",
    "inventor_level = pd.DataFrame()\n",
    "foreign_priority_level = pd.DataFrame()\n",
    "uspcs_level = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "1980 - 1 - 5034\n",
      "<Response [200]>\n",
      "1981 - 1 - 4807\n",
      "<Response [200]>\n",
      "1982 - 1 - 5216\n",
      "<Response [200]>\n",
      "1983 - 1 - 5495\n",
      "<Response [200]>\n",
      "1984 - 1 - 6020\n",
      "<Response [200]>\n",
      "1985 - 1 - 6506\n",
      "<Response [200]>\n",
      "1986 - 1 - 6337\n",
      "<Response [200]>\n",
      "1987 - 1 - 6950\n",
      "<Response [200]>\n",
      "1988 - 1 - 7409\n",
      "<Response [200]>\n",
      "1989 - 1 - 7581\n",
      "<Response [200]>\n",
      "1990 - 1 - 8388\n",
      "<Response [200]>\n",
      "1991 - 1 - 8533\n",
      "<Response [200]>\n",
      "1992 - 1 - 8722\n",
      "<Response [200]>\n",
      "1993 - 1 - 9296\n",
      "<Response [200]>\n",
      "1994 - 1 - 10000\n",
      "<Response [200]>\n",
      "1994 - 2 - 932\n",
      "<Response [200]>\n",
      "1995 - 1 - 10000\n",
      "<Response [200]>\n",
      "1995 - 2 - 1779\n",
      "<Response [200]>\n",
      "1996 - 1 - 10000\n",
      "<Response [200]>\n",
      "1996 - 2 - 2402\n",
      "<Response [200]>\n",
      "1997 - 1 - 10000\n",
      "<Response [200]>\n",
      "1997 - 2 - 3494\n",
      "<Response [200]>\n",
      "1998 - 1 - 10000\n",
      "<Response [200]>\n",
      "1998 - 2 - 4274\n",
      "<Response [200]>\n",
      "1999 - 1 - 10000\n",
      "<Response [200]>\n",
      "1999 - 2 - 4990\n",
      "<Response [200]>\n",
      "2000 - 1 - 10000\n",
      "<Response [200]>\n",
      "2000 - 2 - 5837\n",
      "<Response [200]>\n",
      "2001 - 1 - 10000\n",
      "<Response [200]>\n",
      "2001 - 2 - 5589\n",
      "<Response [200]>\n",
      "2002 - 1 - 10000\n",
      "<Response [200]>\n",
      "2002 - 2 - 7202\n",
      "<Response [200]>\n",
      "2003 - 1 - 10000\n",
      "<Response [200]>\n",
      "2003 - 2 - 8665\n",
      "<Response [200]>\n",
      "2004 - 1 - 10000\n",
      "<Response [200]>\n",
      "2004 - 2 - 9673\n",
      "<Response [200]>\n",
      "2005 - 1 - 10000\n",
      "<Response [200]>\n",
      "2005 - 2 - 10000\n",
      "<Response [200]>\n",
      "2005 - 3 - 966\n",
      "<Response [200]>\n",
      "2006 - 1 - 10000\n",
      "<Response [200]>\n",
      "2006 - 2 - 10000\n",
      "<Response [200]>\n",
      "2006 - 3 - 471\n",
      "<Response [200]>\n",
      "2007 - 1 - 10000\n",
      "<Response [200]>\n",
      "2007 - 2 - 10000\n",
      "<Response [200]>\n",
      "2007 - 3 - 1711\n",
      "<Response [200]>\n",
      "2008 - 1 - 10000\n",
      "<Response [200]>\n",
      "2008 - 2 - 10000\n",
      "<Response [200]>\n",
      "2008 - 3 - 1459\n",
      "<Response [200]>\n",
      "2009 - 1 - 10000\n",
      "<Response [200]>\n",
      "2009 - 2 - 10000\n",
      "<Response [200]>\n",
      "2009 - 3 - 863\n",
      "<Response [200]>\n",
      "2010 - 1 - 10000\n",
      "<Response [200]>\n",
      "2010 - 2 - 10000\n",
      "<Response [200]>\n",
      "2010 - 3 - 3437\n",
      "<Response [200]>\n",
      "2011 - 1 - 10000\n",
      "<Response [200]>\n",
      "2011 - 2 - 10000\n",
      "<Response [200]>\n",
      "2011 - 3 - 4647\n",
      "<Response [200]>\n",
      "2012 - 1 - 10000\n",
      "<Response [200]>\n",
      "2012 - 2 - 10000\n",
      "<Response [200]>\n",
      "2012 - 3 - 6286\n",
      "<Response [200]>\n",
      "2013 - 1 - 10000\n",
      "<Response [200]>\n",
      "2013 - 2 - 10000\n",
      "<Response [200]>\n",
      "2013 - 3 - 8788\n",
      "<Response [503]>\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3ebfd1a03a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                     return complexjson.loads(\n\u001b[0;32m--> 884\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                     )\n\u001b[1;32m    886\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#Due to the limits of the amount of results the API can return, query must be performed in loop by date and page\n",
    "\n",
    "for year in range(1980,2016):\n",
    "    page = 1\n",
    "    more_patents = True\n",
    "    \n",
    "    while more_patents:\n",
    "        \n",
    "        query = \"q={{\\\"_and\\\":[{{\\\"patent_type\\\":\\\"Design\\\"}},{{\\\"_gte\\\":{{\\\"app_date\\\":\\\"{0}-01-01\\\"}}}},{{\\\"_lte\\\":{{\\\"app_date\\\":\\\"{0}-12-31\\\"}}}}]}}\".format(year)\n",
    "        options = \"&o={{\\\"per_page\\\":10000,\\\"page\\\":{}}}\".format(page)\n",
    "\n",
    "        full_url = base_url + query + field_list + options\n",
    "#         print(full_url)\n",
    "        r = requests.get(full_url)\n",
    "        print(r)\n",
    "        data = r.json()\n",
    "        print(year,\"-\",page,\"-\",data['count'])\n",
    "\n",
    "        # several columns in the JSON are nested, which will create a nested dataframe.\n",
    "        # This creates different dataframes for each nested object, which can all be combined later\n",
    "        df = pd.io.json.json_normalize(data['patents'])\n",
    "        top_level = pd.concat([top_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path=['applications'], meta=['patent_number'])\n",
    "        applications_level = pd.concat([applications_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path=['assignees'])\n",
    "        assignee_level = pd.concat([assignee_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path = ['cited_patents'], meta=['patent_number'])\n",
    "        cited_patents_level = pd.concat([cited_patents_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path=['inventors'], meta=['patent_number'])\n",
    "        inventor_level = pd.concat([inventor_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path=['foreign_priority'], meta=['patent_number'])\n",
    "        foreign_priority_level = pd.concat([foreign_priority_level, df], ignore_index=True)\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'], record_path = ['uspcs'], meta=['patent_number'])\n",
    "        uspcs_level = pd.concat([uspcs_level, df], ignore_index=True)\n",
    "\n",
    "\n",
    "        \n",
    "        # decide if to continue to next year or next page\n",
    "        if data['count'] < 10000:\n",
    "            more_patents = False\n",
    "        else:\n",
    "            page += 1\n",
    "            \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5537201, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cited_patents_level.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data isnt available via the API, so it has to be extracted from the raw data downloaded from PatentsView website.\n",
    "This includes the number of non-patent citations and number of figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = pd.read_csv('figures.tsv',delimiter='\\t',usecols=['patent_id','num_figures'])\n",
    "figures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures.rename(index=str, columns={\"patent_id\":\"patent_number\"}, inplace=True)\n",
    "master_df = pd.merge(master_df, figures, how='left',on='patent_number')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherrefs = pd.read_csv('otherreference.tsv', delimiter='\\t', usecols=['uuid','patent_id'], engine='python', error_bad_lines=False)\n",
    "otherrefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherrefs = otherrefs['patent_id'].value_counts().reset_index().rename(index=str, columns={'index':'patent_number','patent_id':'non-pat_refs'})\n",
    "otherrefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(master_df, otherrefs, how='left', on='patent_number')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Now that we have all the basic data that we are interested in, it's time to clean them up into neat pretty rows for useful analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since design patents are designated by an D in the beginning of their number, let's see if any were missclassified. If so, they need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master[~master.patent_number.str.contains('D')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to make sure mis-classified patents are not included\n",
    "def remove_non_design(df):\n",
    "    return df[df.patent_number.str.contains('D')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = remove_non_design(master)\n",
    "\n",
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract application and grant dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(df):\n",
    "    #extract application date and year\n",
    "    df['app_date'] = df['applications'].astype(str).str.extract('(\\d{4}-\\d{2}-\\d{2})')    \n",
    "    df['app_date'] = pd.to_datetime(df['app_date'], errors='coerce').apply(lambda x: x.year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = extract_date(master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract numer of inventors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_inventors(df):\n",
    "    df['num_inventors'] = df['inventors'].str.count(\"inventor_id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = extract_num_inventors(master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract number of assignees, assignees name, city, and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_assignee(df):\n",
    "    df['num_assignees'] = df['assignees'].str.count('assignee_organization')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract number of cited design and utility patents, non-patent prior art, and if any foreign patents were cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_foreign_patents(df):\n",
    "    df['foreign'] = (df['patent_num_foreign_citations'] > 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = any_foreign_patents(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = master.iloc[176,1].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(list1[0]).split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(test.iloc[i,1])\n",
    "# test.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_class(df):\n",
    "    keep = df.copy()\n",
    "    #extract class information\n",
    "    pattern = \"([D0-9]\\d{2}/\\d{1,3}\\.?\\d{1,2})\"\n",
    "\n",
    "    keep['uspcs'] = keep['uspcs'].astype(str).str.findall(pattern)\n",
    "    holder = keep.apply(lambda x: pd.Series(x['uspcs']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    holder.name = 'class'\n",
    "    return keep.drop('uspcs', axis=1).join(holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_missing_citaitons(df):\n",
    "    \n",
    "    \"\"\" Marks patents that have missing citaiton data\n",
    "        \n",
    "        Args:\n",
    "        df(dataframe): the datafame to be cleaned\n",
    "        \n",
    "        Returns:\n",
    "        df(dataframe): the proccessed dataframe with additional columns is_missing(boolean) and num_missing(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    keep = df.copy()\n",
    "\n",
    "    keep['num_cited_returned'] = keep['cited_patents'].astype(str).str.findall('(\\d{7}|D\\d{6})').apply(lambda x: len(x))\n",
    "    keep['patent_num_us_patent_citations'] = keep['patent_num_us_patent_citations'].astype(np.int64)\n",
    "    keep['num_missing'] = keep['patent_num_us_patent_citations'].sub(keep['num_cited_returned'])\n",
    "    keep['is_missing'] = np.where(keep['num_missing'] >0, 1, 0)\n",
    "    \n",
    "    return keep\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = remove_non_design(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('designDirty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = extract_date(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has design patent activity changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = master_df.set_index('patent_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = by_year[['uspcs', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.groupby('year').agg('count').plot(kind='line', legend=False, title=\"USPTO Design patent Activity by Application Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of all patent applications are design patents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_df = pd.DataFrame()\n",
    "field_list = \"&f=[\\\"patent_number\\\",\\\"app_date\\\"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Due to the limits of the amount of results the API can return, query must be performed in loop by date and page\n",
    "\n",
    "for year in range(1993,2016):\n",
    "    page = 1\n",
    "    more_patents = True\n",
    "    \n",
    "    while more_patents:\n",
    "        \n",
    "        query = \"q={{\\\"_and\\\":[{{\\\"patent_type\\\":\\\"Utility\\\"}},{{\\\"_gte\\\":{{\\\"app_date\\\":\\\"{0}-01-01\\\"}}}},{{\\\"_lte\\\":{{\\\"app_date\\\":\\\"{0}-12-31\\\"}}}}]}}\".format(year)\n",
    "        options = \"&o={{\\\"per_page\\\":10000,\\\"page\\\":{}}}\".format(page)\n",
    "\n",
    "        full_url = base_url + query + field_list + options\n",
    "        r = requests.get(full_url)\n",
    "        print(r)\n",
    "        data = r.json()\n",
    "        print(year,\"-\",page,\"-\",data['count'])\n",
    "\n",
    "        \n",
    "        df = pd.io.json.json_normalize(data['patents'])\n",
    "        utility_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "        \n",
    "        # decide if to continue to next year or next page\n",
    "        if data['count'] < 10000:\n",
    "            more_patents = False\n",
    "        else:\n",
    "            page += 1\n",
    "            \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = extract_date(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = extract_class(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.drop(columns = ['cited_patents','patent_num_us_patent_citations','app_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much citation data is missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # master_df = remove_non_design(master_df)\n",
    "# # master_df = extract_date(master_df)\n",
    "# # master_df = extract_class(master_df)\n",
    "# missing = mark_missing_citaitons(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (missing[missing['num_missing'] >0].shape[0]/master_df.shape[0]) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx 54.926% of citation data is missing. This is mostly due to citing patents that were granted before 1976, which is the yeat that patentViews beings coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break it down by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# master_df.groupby(['year']).apply((lambda x: (x[x['num_missing'] > 0].shape[0]/ x.shape[0])*100)).plot(title=\"Percent of Patents with missing Citation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df['test'] = master_df['cited_patents'].astype(str).str.findall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing.drop(columns=['applications','patent_num_us_patent_citations','uspcs','num_cited_returned','num_missing'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = \"([D0-9]\\d{6})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing['cited_patents'] = missing['cited_patents'].astype(str).str.findall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holder = missing.apply(lambda x: pd.Series(x['cited_patents']),axis=1).stack().reset_index(level=1, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holder.name = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing.drop('cited_patents', axis=1).join(holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
